{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent_dir) \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import pymodels.densenetx4 as dn\n",
    "from srcifar100 import *\n",
    "\n",
    "# Imports\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# used for logging to TensorBoard\n",
    "# from tensorboard_logger import configure, log_value\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DenseNet Training')\n",
    "parser.add_argument('--epochs', default=300, type=int,\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int,\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=64, type=int,\n",
    "                    help='mini-batch size (default: 64)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    help='print frequency (default: 10)')\n",
    "parser.add_argument('--layers', default=100, type=int,\n",
    "                    help='total number of layers (default: 100)')\n",
    "parser.add_argument('--growth', default=12, type=int,\n",
    "                    help='number of new channels per layer (default: 12)')\n",
    "parser.add_argument('--droprate', default=0, type=float,\n",
    "                    help='dropout probability (default: 0.0)')\n",
    "parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
    "                    help='whether to use standard augmentation (default: True)')\n",
    "parser.add_argument('--reduce', default=0.5, type=float,\n",
    "                    help='compression rate in transition stage (default: 0.5)')\n",
    "parser.add_argument('--no-bottleneck', dest='bottleneck', action='store_false',\n",
    "                    help='To not use bottleneck block')\n",
    "parser.add_argument('--resume', default='', type=str,\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--name', default='DenseNet_BC_100_12', type=str,\n",
    "                    help='name of experiment')\n",
    "# parser.add_argument('--tensorboard',\n",
    "#                     help='Log progress to TensorBoard', action='store_true')\n",
    "parser.set_defaults(bottleneck=True)\n",
    "parser.set_defaults(augment=True)\n",
    "\n",
    "best_prec1 = 0\n",
    "\n",
    "dbpn_args = ['feat0.conv.weight', 'feat0.conv.bias', 'feat0.act.weight', 'feat1.conv.weight', 'feat1.conv.bias', 'feat1.act.weight', 'up1.up_conv1.deconv.weight', 'up1.up_conv1.deconv.bias', 'up1.up_conv1.act.weight', 'up1.up_conv2.conv.weight', 'up1.up_conv2.conv.bias', 'up1.up_conv2.act.weight', 'up1.up_conv3.deconv.weight', 'up1.up_conv3.deconv.bias', 'up1.up_conv3.act.weight', 'down1.down_conv1.conv.weight', 'down1.down_conv1.conv.bias', 'down1.down_conv1.act.weight', 'down1.down_conv2.deconv.weight', 'down1.down_conv2.deconv.bias', 'down1.down_conv2.act.weight', 'down1.down_conv3.conv.weight', 'down1.down_conv3.conv.bias', 'down1.down_conv3.act.weight', 'up2.up_conv1.deconv.weight', 'up2.up_conv1.deconv.bias', 'up2.up_conv1.act.weight', 'up2.up_conv2.conv.weight', 'up2.up_conv2.conv.bias', 'up2.up_conv2.act.weight', 'up2.up_conv3.deconv.weight', 'up2.up_conv3.deconv.bias', 'up2.up_conv3.act.weight', 'down2.conv.conv.weight', 'down2.conv.conv.bias', 'down2.conv.act.weight', 'down2.down_conv1.conv.weight', 'down2.down_conv1.conv.bias', 'down2.down_conv1.act.weight', 'down2.down_conv2.deconv.weight', 'down2.down_conv2.deconv.bias', 'down2.down_conv2.act.weight', 'down2.down_conv3.conv.weight', 'down2.down_conv3.conv.bias', 'down2.down_conv3.act.weight', 'up3.conv.conv.weight', 'up3.conv.conv.bias', 'up3.conv.act.weight', 'up3.up_conv1.deconv.weight', 'up3.up_conv1.deconv.bias', 'up3.up_conv1.act.weight', 'up3.up_conv2.conv.weight', 'up3.up_conv2.conv.bias', 'up3.up_conv2.act.weight', 'up3.up_conv3.deconv.weight', 'up3.up_conv3.deconv.bias', 'up3.up_conv3.act.weight', 'down3.conv.conv.weight', 'down3.conv.conv.bias', 'down3.conv.act.weight', 'down3.down_conv1.conv.weight', 'down3.down_conv1.conv.bias', 'down3.down_conv1.act.weight', 'down3.down_conv2.deconv.weight', 'down3.down_conv2.deconv.bias', 'down3.down_conv2.act.weight', 'down3.down_conv3.conv.weight', 'down3.down_conv3.conv.bias', 'down3.down_conv3.act.weight', 'up4.conv.conv.weight', 'up4.conv.conv.bias', 'up4.conv.act.weight', 'up4.up_conv1.deconv.weight', 'up4.up_conv1.deconv.bias', 'up4.up_conv1.act.weight', 'up4.up_conv2.conv.weight', 'up4.up_conv2.conv.bias', 'up4.up_conv2.act.weight', 'up4.up_conv3.deconv.weight', 'up4.up_conv3.deconv.bias', 'up4.up_conv3.act.weight', 'down4.conv.conv.weight', 'down4.conv.conv.bias', 'down4.conv.act.weight', 'down4.down_conv1.conv.weight', 'down4.down_conv1.conv.bias', 'down4.down_conv1.act.weight', 'down4.down_conv2.deconv.weight', 'down4.down_conv2.deconv.bias', 'down4.down_conv2.act.weight', 'down4.down_conv3.conv.weight', 'down4.down_conv3.conv.bias', 'down4.down_conv3.act.weight', 'up5.conv.conv.weight', 'up5.conv.conv.bias', 'up5.conv.act.weight', 'up5.up_conv1.deconv.weight', 'up5.up_conv1.deconv.bias', 'up5.up_conv1.act.weight', 'up5.up_conv2.conv.weight', 'up5.up_conv2.conv.bias', 'up5.up_conv2.act.weight', 'up5.up_conv3.deconv.weight', 'up5.up_conv3.deconv.bias', 'up5.up_conv3.act.weight', 'down5.conv.conv.weight', 'down5.conv.conv.bias', 'down5.conv.act.weight', 'down5.down_conv1.conv.weight', 'down5.down_conv1.conv.bias', 'down5.down_conv1.act.weight', 'down5.down_conv2.deconv.weight', 'down5.down_conv2.deconv.bias', 'down5.down_conv2.act.weight', 'down5.down_conv3.conv.weight', 'down5.down_conv3.conv.bias', 'down5.down_conv3.act.weight', 'up6.conv.conv.weight', 'up6.conv.conv.bias', 'up6.conv.act.weight', 'up6.up_conv1.deconv.weight', 'up6.up_conv1.deconv.bias', 'up6.up_conv1.act.weight', 'up6.up_conv2.conv.weight', 'up6.up_conv2.conv.bias', 'up6.up_conv2.act.weight', 'up6.up_conv3.deconv.weight', 'up6.up_conv3.deconv.bias', 'up6.up_conv3.act.weight', 'down6.conv.conv.weight', 'down6.conv.conv.bias', 'down6.conv.act.weight', 'down6.down_conv1.conv.weight', 'down6.down_conv1.conv.bias', 'down6.down_conv1.act.weight', 'down6.down_conv2.deconv.weight', 'down6.down_conv2.deconv.bias', 'down6.down_conv2.act.weight', 'down6.down_conv3.conv.weight', 'down6.down_conv3.conv.bias', 'down6.down_conv3.act.weight', 'up7.conv.conv.weight', 'up7.conv.conv.bias', 'up7.conv.act.weight', 'up7.up_conv1.deconv.weight', 'up7.up_conv1.deconv.bias', 'up7.up_conv1.act.weight', 'up7.up_conv2.conv.weight', 'up7.up_conv2.conv.bias', 'up7.up_conv2.act.weight', 'up7.up_conv3.deconv.weight', 'up7.up_conv3.deconv.bias', 'up7.up_conv3.act.weight', 'output_conv.conv.weight', 'output_conv.conv.bias', 'conv1.weight']\n",
    "densenet_args = ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn1.running_mean', 'block1.layer.0.bn1.running_var', 'block1.layer.0.conv1.weight', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn1.running_mean', 'block1.layer.1.bn1.running_var', 'block1.layer.1.conv1.weight', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn1.running_mean', 'block1.layer.2.bn1.running_var', 'block1.layer.2.conv1.weight', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn1.running_mean', 'block1.layer.3.bn1.running_var', 'block1.layer.3.conv1.weight', 'block1.layer.4.bn1.weight', 'block1.layer.4.bn1.bias', 'block1.layer.4.bn1.running_mean', 'block1.layer.4.bn1.running_var', 'block1.layer.4.conv1.weight', 'block1.layer.5.bn1.weight', 'block1.layer.5.bn1.bias', 'block1.layer.5.bn1.running_mean', 'block1.layer.5.bn1.running_var', 'block1.layer.5.conv1.weight', 'block1.layer.6.bn1.weight', 'block1.layer.6.bn1.bias', 'block1.layer.6.bn1.running_mean', 'block1.layer.6.bn1.running_var', 'block1.layer.6.conv1.weight', 'block1.layer.7.bn1.weight', 'block1.layer.7.bn1.bias', 'block1.layer.7.bn1.running_mean', 'block1.layer.7.bn1.running_var', 'block1.layer.7.conv1.weight', 'block1.layer.8.bn1.weight', 'block1.layer.8.bn1.bias', 'block1.layer.8.bn1.running_mean', 'block1.layer.8.bn1.running_var', 'block1.layer.8.conv1.weight', 'block1.layer.9.bn1.weight', 'block1.layer.9.bn1.bias', 'block1.layer.9.bn1.running_mean', 'block1.layer.9.bn1.running_var', 'block1.layer.9.conv1.weight', 'block1.layer.10.bn1.weight', 'block1.layer.10.bn1.bias', 'block1.layer.10.bn1.running_mean', 'block1.layer.10.bn1.running_var', 'block1.layer.10.conv1.weight', 'block1.layer.11.bn1.weight', 'block1.layer.11.bn1.bias', 'block1.layer.11.bn1.running_mean', 'block1.layer.11.bn1.running_var', 'block1.layer.11.conv1.weight', 'trans1.bn1.weight', 'trans1.bn1.bias', 'trans1.bn1.running_mean', 'trans1.bn1.running_var', 'trans1.conv1.weight', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn1.running_mean', 'block2.layer.0.bn1.running_var', 'block2.layer.0.conv1.weight', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn1.running_mean', 'block2.layer.1.bn1.running_var', 'block2.layer.1.conv1.weight', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn1.running_mean', 'block2.layer.2.bn1.running_var', 'block2.layer.2.conv1.weight', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn1.running_mean', 'block2.layer.3.bn1.running_var', 'block2.layer.3.conv1.weight', 'block2.layer.4.bn1.weight', 'block2.layer.4.bn1.bias', 'block2.layer.4.bn1.running_mean', 'block2.layer.4.bn1.running_var', 'block2.layer.4.conv1.weight', 'block2.layer.5.bn1.weight', 'block2.layer.5.bn1.bias', 'block2.layer.5.bn1.running_mean', 'block2.layer.5.bn1.running_var', 'block2.layer.5.conv1.weight', 'block2.layer.6.bn1.weight', 'block2.layer.6.bn1.bias', 'block2.layer.6.bn1.running_mean', 'block2.layer.6.bn1.running_var', 'block2.layer.6.conv1.weight', 'block2.layer.7.bn1.weight', 'block2.layer.7.bn1.bias', 'block2.layer.7.bn1.running_mean', 'block2.layer.7.bn1.running_var', 'block2.layer.7.conv1.weight', 'block2.layer.8.bn1.weight', 'block2.layer.8.bn1.bias', 'block2.layer.8.bn1.running_mean', 'block2.layer.8.bn1.running_var', 'block2.layer.8.conv1.weight', 'block2.layer.9.bn1.weight', 'block2.layer.9.bn1.bias', 'block2.layer.9.bn1.running_mean', 'block2.layer.9.bn1.running_var', 'block2.layer.9.conv1.weight', 'block2.layer.10.bn1.weight', 'block2.layer.10.bn1.bias', 'block2.layer.10.bn1.running_mean', 'block2.layer.10.bn1.running_var', 'block2.layer.10.conv1.weight', 'block2.layer.11.bn1.weight', 'block2.layer.11.bn1.bias', 'block2.layer.11.bn1.running_mean', 'block2.layer.11.bn1.running_var', 'block2.layer.11.conv1.weight', 'trans2.bn1.weight', 'trans2.bn1.bias', 'trans2.bn1.running_mean', 'trans2.bn1.running_var', 'trans2.conv1.weight', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn1.running_mean', 'block3.layer.0.bn1.running_var', 'block3.layer.0.conv1.weight', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn1.running_mean', 'block3.layer.1.bn1.running_var', 'block3.layer.1.conv1.weight', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn1.running_mean', 'block3.layer.2.bn1.running_var', 'block3.layer.2.conv1.weight', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn1.running_mean', 'block3.layer.3.bn1.running_var', 'block3.layer.3.conv1.weight', 'block3.layer.4.bn1.weight', 'block3.layer.4.bn1.bias', 'block3.layer.4.bn1.running_mean', 'block3.layer.4.bn1.running_var', 'block3.layer.4.conv1.weight', 'block3.layer.5.bn1.weight', 'block3.layer.5.bn1.bias', 'block3.layer.5.bn1.running_mean', 'block3.layer.5.bn1.running_var', 'block3.layer.5.conv1.weight', 'block3.layer.6.bn1.weight', 'block3.layer.6.bn1.bias', 'block3.layer.6.bn1.running_mean', 'block3.layer.6.bn1.running_var', 'block3.layer.6.conv1.weight', 'block3.layer.7.bn1.weight', 'block3.layer.7.bn1.bias', 'block3.layer.7.bn1.running_mean', 'block3.layer.7.bn1.running_var', 'block3.layer.7.conv1.weight', 'block3.layer.8.bn1.weight', 'block3.layer.8.bn1.bias', 'block3.layer.8.bn1.running_mean', 'block3.layer.8.bn1.running_var', 'block3.layer.8.conv1.weight', 'block3.layer.9.bn1.weight', 'block3.layer.9.bn1.bias', 'block3.layer.9.bn1.running_mean', 'block3.layer.9.bn1.running_var', 'block3.layer.9.conv1.weight', 'block3.layer.10.bn1.weight', 'block3.layer.10.bn1.bias', 'block3.layer.10.bn1.running_mean', 'block3.layer.10.bn1.running_var', 'block3.layer.10.conv1.weight', 'block3.layer.11.bn1.weight', 'block3.layer.11.bn1.bias', 'block3.layer.11.bn1.running_mean', 'block3.layer.11.bn1.running_var', 'block3.layer.11.conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'fc.weight', 'fc.bias']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(arg_string):\n",
    "    global args, best_prec1\n",
    "    #setting up integrating the two models\n",
    "    current_dir = os.getcwd()\n",
    "#     current_dir = '/datasets/ee285s-public/'\n",
    "#     model_path = os.path.join(current_dir,'models/DBPN_x2.pth')\n",
    "#     upscale_factor = 8 # Can be 2, 4 or 8\n",
    "    cuda = True # Set True if you're using GPU\n",
    "    gpus=2\n",
    "\n",
    "    seed = 123\n",
    "    \n",
    "    arg_list = arg_string.split()\n",
    "    args = parser.parse_args(arg_list) #Adjusted for arguements\n",
    "#     if args.tensorboard: configure(\"runs/%s\"%(args.name))\n",
    "    \n",
    "    # Data loading code\n",
    "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "    \n",
    "    if args.augment:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((128,128),Image.BICUBIC), #x24 scaling\n",
    "            transforms.RandomCrop(128, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            ])\n",
    "    else:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.\n",
    "            normalize,\n",
    "            ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((128,128),Image.BICUBIC), #x2 scaling\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "        ])\n",
    "    \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "#     train_loader = torch.utils.data.DataLoader(SRCIFAR100(os.path.join(current_dir,'X4CIFAR100'), transform_train), batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "#     val_loader = torch.utils.data.DataLoader(SRCIFAR100(os.path.join(current_dir,'X4CIFAR100_t'), transform_test), batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    train_file = '/train.npy'\n",
    "    test_file = '/test.npy'\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR100(os.path.join('/datasets/ee285s-public/'), train=True, download=True,\n",
    "                         transform=transform_train),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR100(os.path.join('/datasets/ee285s-public/'), train=False, transform=transform_test),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    # create model\n",
    "    model = dn.DenseNet3(args.layers, 100, args.growth, reduction=args.reduce,\n",
    "                         bottleneck=args.bottleneck, dropRate=args.droprate)\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "    # get the number of model parameters\n",
    "    print('Number of model parameters: {}'.format(\n",
    "        sum([p.data.nelement() for p in model.parameters()])))\n",
    "    \n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    # define loss function (criterion) and pptimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                nesterov=True,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # train for one epoch\n",
    "        prec2 = train(train_loader, model, criterion, optimizer, epoch)\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion, epoch)\n",
    "        \n",
    "        if (epoch == 0):\n",
    "            np.save(current_dir + train_file,prec2)\n",
    "            np.save(current_dir + test_file,prec1)\n",
    "        else:\n",
    "            train_acc = np.load(current_dir + train_file)\n",
    "            test_acc = np.load(current_dir + test_file)\n",
    "            t_val = prec2\n",
    "            v_val = prec1\n",
    "            np.save(current_dir + train_file,np.array(np.append(train_acc,t_val)))\n",
    "            np.save(current_dir + test_file,np.array(np.append(test_acc,v_val)))\n",
    "        \n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "#         print(model.state_dict())\n",
    "        \n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        }, is_best)\n",
    "    print('Best accuracy: ', best_prec1)\n",
    "    \n",
    "    train_acc = np.load(current_dir + train_file)\n",
    "    test_acc = np.load(current_dir + test_file)\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"Train for one epoch on the training set\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        target = target.cuda(async=True)\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        \n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      loss=losses, top1=top1))\n",
    "    return top1.avg\n",
    "    # log to TensorBoard\n",
    "#     if args.tensorboard:\n",
    "#         log_value('train_loss', losses.avg, epoch)\n",
    "#         log_value('train_acc', top1.avg, epoch)\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch):\n",
    "    \"\"\"Perform validation on the validation set\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda(async=True)\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                      top1=top1))\n",
    "        \n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    # log to TensorBoard\n",
    "#     if args.tensorboard:\n",
    "#         log_value('val_loss', losses.avg, epoch)\n",
    "#         log_value('val_acc', top1.avg, epoch)\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"Saves checkpoint to disk\"\"\"\n",
    "    directory = \"../models/%s/\"%(args.name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = directory + filename\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, '../models/%s/'%(args.name) + 'model_best.pth.tar')\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
    "    # log to TensorBoard\n",
    "#     if args.tensorboard:\n",
    "#         log_value('learning_rate', lr, epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of model parameters: 228004\n",
      "=> no checkpoint found at '../models/DenseNet-20-12-bi-x4/checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:146: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:147: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/782]\tTime 3.413 (3.413)\tLoss 4.6674 (4.6674)\tPrec@1 1.562 (1.562)\n",
      "Epoch: [0][10/782]\tTime 0.234 (0.504)\tLoss 4.6767 (4.6481)\tPrec@1 0.000 (0.994)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fcbb36f3048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4458) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0f78b6ab43e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0marg_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"--layers 20 --growth 12 -b 64 --no-bottleneck --reduce 1.0 --name DenseNet-20-12-bi-x4 --resume ../models/DenseNet-20-12-bi-x4/checkpoint.pth.tar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-cbaef7662cfc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arg_string)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mprec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-cbaef7662cfc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mtarget_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new = False\n",
    "if new:\n",
    "    arpg_string = \"--layers 20 --growth 12 -b 64 --no-bottleneck --reduce 1.0 --name DenseNet-20-12-bi-x4\"\n",
    "else:\n",
    "    arg_string = \"--layers 20 --growth 12 -b 64 --no-bottleneck --reduce 1.0 --name DenseNet-20-12-bi-x4 --resume ../models/DenseNet-20-12-bi-x4/checkpoint.pth.tar\"\n",
    "train_acc, test_acc = main(arg_string)\n",
    "plt.figure()\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "train_acc = np.load(current_dir + '/train.npy')\n",
    "test_acc = np.load(current_dir + '/test.npy')\n",
    "plt.figure()\n",
    "plt.plot(100-train_acc)\n",
    "plt.plot(100-test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
